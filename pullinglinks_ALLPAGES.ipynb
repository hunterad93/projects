{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different strategy idea for getting listing urls in this notebook:\n",
    "\n",
    "This page has every craigslist website location: https://geo.craigslist.org/iso/us\n",
    "\n",
    "loop through all these with base query: <city>.craigslist.org/search/cta?bundleDuplicates=1&postedToday=1&purveyor=owner#search=1~gallery~0~0 (this is filtering to what was posted today and being sold by owner, but if we are running constantly this seems like the way?)\n",
    "\n",
    "within each loop, loop through all gallery~x~ to get all listings from pages after first page for that city\n",
    "\n",
    "create dictionary with url list as value per city key\n",
    "\n",
    "create a dictionary with df as value per city key\n",
    "\n",
    "I guess only real benefit of this approach is not having to worry about crafting search queries with make and model?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First cell gets a list of all craigslist cities and sets a base_query, search filters are part of URL, can customize further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
    "text": [
    "abilene: ['https://abilene.craigslist.org/cto/d/abilene-2009-ford-150-xlt-supercrew-46l/7633020403.html', 'https://abilene.craigslist.org/cto/d/abilene-studebaker-1961/7632988630.html']\n",
    "akroncanton:..."
   ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# URL for all Craigslist locations\n",
    "base_url = \"https://geo.craigslist.org/iso/us\"\n",
    "\n",
    "# Fetch the page with all Craigslist locations\n",
    "response = requests.get(base_url)\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the container with all city links\n",
    "container = soup.find('div', class_='geo-site-list-container')\n",
    "\n",
    "# Find all <a> elements within the container and extract hrefs (which should be URLs for Craigslist websites)\n",
    "city_urls = [element[\"href\"] for element in container.find_all(\"a\", href=True)]\n",
    "\n",
    "print(city_urls)\n",
    "\n",
    "# Query to append to each city URL\n",
    "base_query = \"/search/cta?bundleDuplicates=1&postedToday=1&purveyor=owner#search=1~gallery~0~0\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second cell defines scrape_pages function which uses selenium and loops through all pages of a city+base query combo, and adds all listing urls to a dictionary that would eventually include all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {"tags": [
           "output_scroll"
       ]},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abilene: ['https://abilene.craigslist.org/cto/d/abilene-2009-ford-150-xlt-supercrew-46l/7633020403.html', 'https://abilene.craigslist.org/cto/d/abilene-studebaker-1961/7632988630.html', 'https://abilene.craigslist.org/cto/d/abilene-2017-nissan-titan-sl-4x4/7632917871.html']\n",
      "akroncanton: ['https://akroncanton.craigslist.org/cto/d/streetsboro-2014-subaru-outback-25i/7633037225.html', 'https://akroncanton.craigslist.org/cto/d/sharon-center-2010-honda-fit-sport/7632989845.html', 'https://akroncanton.craigslist.org/cto/d/akron-2007-toyota-avalon-runs-excellent/7632986540.html', 'https://akroncanton.craigslist.org/cto/d/akron-2012-cadillac-escalade-runs/7632981939.html', 'https://akroncanton.craigslist.org/cto/d/canton-1996-buick-park-avenue-ultra/7632972040.html', 'https://akroncanton.craigslist.org/cto/d/canton-2005-astro-van-awd/7632927819.html', 'https://akroncanton.craigslist.org/cto/d/wooster-2006-honda-civic-ex/7632898047.html', 'https://akroncanton.craigslist.org/cto/d/kent-2008-mercedes-ml350/7632870445.html', 'https://akroncanton.craigslist.org/cto/d/middlebranch-jeep-patriot-2013-latitude/7632855460.html', 'https://akroncanton.craigslist.org/cto/d/barberton-2009-chrysler-town-and/7632836417.html', 'https://akroncanton.craigslist.org/cto/d/cleveland-1993-mustang-coupe-project/7632749825.html']\n",
      ..."
     ]
    }
   ],
   "source": [
    "def scrape_pages(base_url):\n",
    "    i = 0\n",
    "    all_urls = []\n",
    "\n",
    "    # Extract the city name from the base_url\n",
    "    city_name = base_url.split(\"//\")[1].split(\".\")[0]\n",
    "\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "    # Set up the webdriver\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Append the page number to the URL\n",
    "            url = base_url + \"#search=1~gallery~\" + str(i) + \"~0\"\n",
    "            # Fetch the page\n",
    "            driver.get(url)\n",
    "            # Parse the page with BeautifulSoup\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            # Find all <a> elements with class=\"titlestring\" and an href attribute\n",
    "            elements = soup.find_all(\"a\", class_=\"titlestring\", href=True)\n",
    "\n",
    "            # Extract the href attribute from each element and store them in the \"urls\" list\n",
    "            # Ignores ones that are in the 'search wider area' section of page by checking for city name\n",
    "            urls = [element[\"href\"] for element in elements if city_name in element[\"href\"]]\n",
    "\n",
    "            # Check if the newly scraped page has any new URLs\n",
    "            # This is because if you go beyond the limit of search results, it redirects to last page with actual results\n",
    "            if not urls or (set(urls).issubset(set(all_urls))):\n",
    "                break  # If not, break the loop\n",
    "\n",
    "            #Im betting these two tests are very very inefficient and should be revisited\n",
    "\n",
    "            # Extend the all_urls list with the URLs from this page\n",
    "            all_urls.extend(urls)\n",
    "\n",
    "            # Increment the page number\n",
    "            i += 1\n",
    "\n",
    "            # Sleep for a short period to avoid making too many requests in a short period of time\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "    return all_urls\n",
    "\n",
    "\n",
    "# Dictionary to hold city names and corresponding URLs\n",
    "city_url_dict = {}\n",
    "\n",
    "# Loop through all Craigslist website URLs\n",
    "for city_url in city_urls:\n",
    "    # Extract the city name from the URL\n",
    "    city_name = city_url.split(\"//\")[1].split(\".\")[0]\n",
    "\n",
    "    # Append the base query to the city URL\n",
    "    base_query = city_url + \"/search/cta?bundleDuplicates=1&postedToday=1&purveyor=owner\"\n",
    "    \n",
    "    # Call the scrape_pages function and store the results in the dictionary\n",
    "    city_url_dict[city_name] = scrape_pages(base_query)\n",
    "\n",
    "# Print the dictionary\n",
    "for city, urls in city_url_dict.items():\n",
    "    print(f\"{city}: {urls}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here it is just code parsing listing page html mostly, this cell defines some functions for parsing different sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name(name):\n",
    "    year_pattern = r'\\b\\d{4}\\b'\n",
    "    make_model_pattern = r'\\b([A-Za-z]+)\\s+([A-Za-z0-9-]+)'\n",
    "    \n",
    "    year_match = re.search(year_pattern, name)\n",
    "    make_model_match = re.search(make_model_pattern, name)\n",
    "\n",
    "    year = year_match.group(0) if year_match else None\n",
    "    make, model = make_model_match.groups() if make_model_match else (None, None)\n",
    "\n",
    "    return make, model, year\n",
    "\n",
    "def parse_attrgroup(soup):    \n",
    "    car_name = soup.find('p', class_='attrgroup')\n",
    "    if car_name is not None:\n",
    "        car_name = car_name.find('b').text.strip()\n",
    "    # Extract latitude and longitude\n",
    "    map_div = soup.find('div', {'id': 'map'})\n",
    "    latitude = float(map_div['data-latitude'])\n",
    "    longitude = float(map_div['data-longitude'])\n",
    "\n",
    "    # Extract attributes\n",
    "    attrgroup = soup.find_all('p', class_='attrgroup')\n",
    "    attributes = {}\n",
    "    for group in attrgroup:\n",
    "        for span in group.find_all('span'):\n",
    "            if ':' in span.text:\n",
    "                key, value = span.text.split(':')\n",
    "                attributes[key.strip()] = value.strip()\n",
    "\n",
    "    # Extract make, model, and year\n",
    "    make, model, year = parse_name(car_name)  # Pass the car_name variable to the parse_name function\n",
    "\n",
    "    parsed_data = {\n",
    "        'Title Status': attributes.get('title status'),\n",
    "        'Paint Color': attributes.get('paint color'),\n",
    "        'Odometer': int(attributes.get('odometer')),\n",
    "        'Drive': attributes.get('drive'),\n",
    "        'Condition': attributes.get('condition'),\n",
    "        'Make': make,\n",
    "        'Model': model,\n",
    "        'Year': year\n",
    "    }\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "def parse_ld_posting_data(soup):\n",
    "    script_tag = soup.find('script', {'id': 'ld_posting_data'})\n",
    "    json_data = json.loads(script_tag.string)\n",
    "    description = json_data['description']\n",
    "    price = json_data['offers']['price']\n",
    "    latitude = json_data['offers']['availableAtOrFrom']['geo']['latitude']\n",
    "    longitude = json_data['offers']['availableAtOrFrom']['geo']['longitude']\n",
    "\n",
    "    parsed_listing = {\n",
    "        'Price': price,\n",
    "        'Description': description,\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude\n",
    "    }\n",
    "    return parsed_listing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell calls the parsing function on the massive list of urls, organizing resulting dfs into a dictionary with city names as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {"tags": [
           "output_scroll"
       ]},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping URL https://amarillo.craigslist.org/cto/d/amarillo-2018-gmc-yukon-denali/7632851119.html - script_tag not found\n",
      "Skipping URL https://athensga.craigslist.org/cto/d/auburn-98-dodge-ram-truck-2700-obo/7633011689.html - script_tag not found\n",
      ... https://zanesville.craigslist.org/cto/d/chandlersville-1950-ford-door-sedan/7632958084.html - script_tag not found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>Miles</th>\n",
       "      <th>Price</th>\n",
       "      <th>Title</th>\n",
       "      <th>Paint</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Description</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subaru</td>\n",
       "      <td>outback</td>\n",
       "      <td>2014</td>\n",
       "      <td>156000</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>silver</td>\n",
       "      <td>None</td>\n",
       "      <td>good</td>\n",
       "      <td>2014 Subaru Outback 2.5i Limited  AWD, New tir...</td>\n",
       "      <td>41.252000</td>\n",
       "      <td>-81.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>honda</td>\n",
       "      <td>fit</td>\n",
       "      <td>2010</td>\n",
       "      <td>134186</td>\n",
       "      <td>6950.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>blue</td>\n",
       "      <td>fwd</td>\n",
       "      <td>excellent</td>\n",
       "      <td>2010 Honda Fit automatic 5 speed with overdriv...</td>\n",
       "      <td>41.121100</td>\n",
       "      <td>-81.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toyota</td>\n",
       "      <td>avalon</td>\n",
       "      <td>2007</td>\n",
       "      <td>120513</td>\n",
       "      <td>6450.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>black</td>\n",
       "      <td>fwd</td>\n",
       "      <td>excellent</td>\n",
       "      <td>2007 Toyota Avalon, Sedan, Front Wheel Drive  ...</td>\n",
       "      <td>41.044900</td>\n",
       "      <td>-81.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cadillac</td>\n",
       "      <td>escalade</td>\n",
       "      <td>2012</td>\n",
       "      <td>166321</td>\n",
       "      <td>12900.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>black</td>\n",
       "      <td>4wd</td>\n",
       "      <td>excellent</td>\n",
       "      <td>2012 Cadillac Escalade AWD 4dr Premium  SUV, A...</td>\n",
       "      <td>41.044900</td>\n",
       "      <td>-81.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buick</td>\n",
       "      <td>park</td>\n",
       "      <td>1996</td>\n",
       "      <td>159453</td>\n",
       "      <td>2750.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>purple</td>\n",
       "      <td>fwd</td>\n",
       "      <td>fair</td>\n",
       "      <td>96 Buick Park Avenue Ultra Supercharged 4 Door...</td>\n",
       "      <td>40.795098</td>\n",
       "      <td>-81.319835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chevy</td>\n",
       "      <td>astro</td>\n",
       "      <td>2005</td>\n",
       "      <td>238000</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>white</td>\n",
       "      <td>4wd</td>\n",
       "      <td>good</td>\n",
       "      <td>05 astro van, the last year they were made.  2...</td>\n",
       "      <td>40.846500</td>\n",
       "      <td>-81.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>honda</td>\n",
       "      <td>civic</td>\n",
       "      <td>2006</td>\n",
       "      <td>226986</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>white</td>\n",
       "      <td>fwd</td>\n",
       "      <td>good</td>\n",
       "      <td>Runs and shifts great and doesn't have any maj...</td>\n",
       "      <td>40.797674</td>\n",
       "      <td>-81.905444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mercedes</td>\n",
       "      <td>benz</td>\n",
       "      <td>2008</td>\n",
       "      <td>145000</td>\n",
       "      <td>6500.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2008 Mercedes ML350 w/ 145,000 miles, drives v...</td>\n",
       "      <td>41.144900</td>\n",
       "      <td>-81.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jeep</td>\n",
       "      <td>patriot</td>\n",
       "      <td>2013</td>\n",
       "      <td>158000</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>black</td>\n",
       "      <td>fwd</td>\n",
       "      <td>excellent</td>\n",
       "      <td>2013 Jeep Patriot Latitude    2.4L automatic  ...</td>\n",
       "      <td>40.883400</td>\n",
       "      <td>-81.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chrysler</td>\n",
       "      <td>town</td>\n",
       "      <td>2009</td>\n",
       "      <td>170000</td>\n",
       "      <td>4900.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2009 chrysler Town n Country Touring  Fully lo...</td>\n",
       "      <td>41.019700</td>\n",
       "      <td>-81.621200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ford</td>\n",
       "      <td>mustang</td>\n",
       "      <td>1993</td>\n",
       "      <td>158836</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>clean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>My loss of time and interest is your possible ...</td>\n",
       "      <td>41.389700</td>\n",
       "      <td>-81.735100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Make     Model  Year   Miles     Price  Title   Paint Drive  \\\n",
       "0     subaru   outback  2014  156000  10000.00  clean  silver  None   \n",
       "1      honda       fit  2010  134186   6950.00  clean    blue   fwd   \n",
       "2     toyota    avalon  2007  120513   6450.00  clean   black   fwd   \n",
       "3   cadillac  escalade  2012  166321  12900.00  clean   black   4wd   \n",
       "4      buick      park  1996  159453   2750.00  clean  purple   fwd   \n",
       "5      chevy     astro  2005  238000   4000.00  clean   white   4wd   \n",
       "6      honda     civic  2006  226986   1500.00  clean   white   fwd   \n",
       "7   mercedes      benz  2008  145000   6500.00  clean    None  None   \n",
       "8       jeep   patriot  2013  158000   5000.00  clean   black   fwd   \n",
       "9   chrysler      town  2009  170000   4900.00  clean    None  None   \n",
       "10      ford   mustang  1993  158836   5000.00  clean    None  None   \n",
       "\n",
       "    Condition                                        Description   Latitude  \\\n",
       "0        good  2014 Subaru Outback 2.5i Limited  AWD, New tir...  41.252000   \n",
       "1   excellent  2010 Honda Fit automatic 5 speed with overdriv...  41.121100   \n",
       "2   excellent  2007 Toyota Avalon, Sedan, Front Wheel Drive  ...  41.044900   \n",
       "3   excellent  2012 Cadillac Escalade AWD 4dr Premium  SUV, A...  41.044900   \n",
       "4        fair  96 Buick Park Avenue Ultra Supercharged 4 Door...  40.795098   \n",
       "5        good  05 astro van, the last year they were made.  2...  40.846500   \n",
       "6        good  Runs and shifts great and doesn't have any maj...  40.797674   \n",
       "7        None  2008 Mercedes ML350 w/ 145,000 miles, drives v...  41.144900   \n",
       "8   excellent  2013 Jeep Patriot Latitude    2.4L automatic  ...  40.883400   \n",
       "9        None  2009 chrysler Town n Country Touring  Fully lo...  41.019700   \n",
       "10       None  My loss of time and interest is your possible ...  41.389700   \n",
       "\n",
       "     Longitude  \n",
       "0   -81.342000  \n",
       "1   -81.750800  \n",
       "2   -81.520000  \n",
       "3   -81.520000  \n",
       "4   -81.319835  \n",
       "5   -81.440800  \n",
       "6   -81.905444  \n",
       "7   -81.349800  \n",
       "8   -81.332800  \n",
       "9   -81.621200  \n",
       "10  -81.735100  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the extracted data\n",
    "columns = ['Make', 'Model', 'Year', 'Miles', 'Price', 'Title', 'Paint', 'Drive', 'Condition', 'Description', 'Latitude', 'Longitude']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Create an empty dictionary to hold DataFrames for each city\n",
    "city_df_dict = {}\n",
    "\n",
    "for city, urls in city_url_dict.items():\n",
    "    # Initialize an empty DataFrame for each city\n",
    "    df = pd.DataFrame(columns=['Make', 'Model', 'Year', 'Miles', 'Price', 'Title', 'Paint', 'Drive', 'Condition', 'Description', 'Latitude', 'Longitude'])\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            script_tag = soup.find('script', {'id': 'ld_posting_data'})\n",
    "\n",
    "            if script_tag is None:\n",
    "                print(f\"Skipping URL {url} - script_tag not found\")\n",
    "                continue\n",
    "\n",
    "            json_data = json.loads(script_tag.string)\n",
    "\n",
    "            # Extract relevant fields via dictionaries which are outputs from functions above\n",
    "            parsed_data = parse_attrgroup(soup)\n",
    "            parsed_listing = parse_ld_posting_data(soup)\n",
    "\n",
    "            # Append the extracted data to the DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'Make': [parsed_data['Make']],\n",
    "                'Model': [parsed_data['Model']],\n",
    "                'Year': [parsed_data['Year']],\n",
    "                'Miles': [parsed_data['Odometer']],\n",
    "                'Price': [parsed_listing['Price']],\n",
    "                'Title': [parsed_data['Title Status']],\n",
    "                'Paint': [parsed_data['Paint Color']],\n",
    "                'Drive': [parsed_data['Drive']],\n",
    "                'Condition': [parsed_data['Condition']],\n",
    "                'Description': [parsed_listing['Description']],\n",
    "                'Latitude': [parsed_listing['Latitude']],\n",
    "                'Longitude': [parsed_listing['Longitude']],\n",
    "            })\n",
    "\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "            \n",
    "        except AttributeError as e:\n",
    "            print(f\"Skipping URL {url} - Error: {e}\")\n",
    "\n",
    "    # Save the DataFrame for this city to the dictionary\n",
    "    city_df_dict[city] = df\n",
    "\n",
    "\n",
    "city_df_dict[\"akroncanton\"]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craigslist-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
